spark:
  image:
    registry: docker.io
    repository: bitnami/spark
    tag: 3.5.3-debian-12-r1
    digest: ""
  ## Spark master specific configuration
  ##
  master:
    containerPorts:
      http: 8080
      https: 8480
      cluster: 7077
    ## @param master.extraEnvVars Extra environment variables to pass to the master container
    ## For example:
    ## extraEnvVars:
    ##  - name: SPARK_DAEMON_JAVA_OPTS
    ##    value: -Dx=y
    ##
    extraEnvVars: []

  ## @section Spark worker parameters
  ##

  ## Spark worker specific configuration
  ##
  worker:
    containerPorts:
      http: 8080
      https: 8480
      cluster: ""
    ## Autoscaling parameters
    ## @param worker.autoscaling.enabled Enable replica autoscaling depending on CPU
    ## @param worker.autoscaling.minReplicas Minimum number of worker replicas
    ## @param worker.autoscaling.maxReplicas Maximum number of worker replicas
    ## @param worker.autoscaling.targetCPU Target CPU utilization percentage
    ## @param worker.autoscaling.targetMemory Target Memory utilization percentage
    ##
    autoscaling:
      enabled: false
      minReplicas: ""
      maxReplicas: 5
      targetCPU: 50
      targetMemory: ""

  ingress:
    ## @param ingress.enabled Enable ingress controller resource
    ##
    enabled: false
    ## @param ingress.pathType Ingress path type
    ##
    pathType: ImplementationSpecific
    ## @param ingress.ingressClassName IngressClass that will be be used to implement the Ingress (Kubernetes 1.18+)
    ingressClassName: ""
    ## @param ingress.path The Path to Spark. You may need to set this to '/*' in order to use this with ALB ingress controllers.
    ##
    path: /
    ## @param ingress.annotations Additional annotations for the Ingress resource. To enable certificate autogeneration, place here your cert-manager annotations.
    annotations: {}
    ## @param ingress.tls Enable TLS configuration for the hostname defined at ingress.hostname parameter
    ## TLS certificates will be retrieved from a TLS secret with name: {{- printf "%s-tls" .Values.ingress.hostname }}
    tls: false

  ## Metrics configuration
  ##
  metrics:
    ## @param metrics.enabled Start a side-car prometheus exporter
    ##
    enabled: true
    ## Prometheus Service Monitor
    ## ref: https://github.com/coreos/prometheus-operator
    ##      https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#endpoint
    ##
    podMonitor:
      ## @param metrics.podMonitor.enabled If the operator is installed in your cluster, set to true to create a PodMonitor Resource for scraping metrics using PrometheusOperator
      ##
      enabled: false
      ## @param metrics.podMonitor.extraMetricsEndpoints Add metrics endpoints for monitoring the jobs running in the worker nodes
      ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#podmetricsendpoint
      ## e.g:
      ## - port: myapp
      ##   path: /metrics/
      ##
      extraMetricsEndpoints: []
      ## @param metrics.podMonitor.namespace Specify the namespace in which the podMonitor resource will be created
      ##
      namespace: ""
      ## @param metrics.podMonitor.interval Specify the interval at which metrics should be scraped
      ##
      interval: 30s
      ## @param metrics.podMonitor.scrapeTimeout Specify the timeout after which the scrape is ended
      ## e.g:
      ## scrapeTimeout: 30s
      ##
      scrapeTimeout: ""
      ## @param metrics.podMonitor.additionalLabels Additional labels that can be used so PodMonitors will be discovered by Prometheus
      ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#prometheusspec
      ##
      additionalLabels: {}
    ## Custom PrometheusRule to be defined
    ## The value is evaluated as a template, so, for example, the value can depend on .Release or .Chart
    ## ref: https://github.com/coreos/prometheus-operator#customresourcedefinitions
    ##
    prometheusRule:
      ## @param metrics.prometheusRule.enabled Set this to true to create prometheusRules for Prometheus
      ##
      enabled: false
      ## @param metrics.prometheusRule.namespace Namespace where the prometheusRules resource should be created
      ##
      namespace: ""
      ## @param metrics.prometheusRule.additionalLabels Additional labels that can be used so prometheusRules will be discovered by Prometheus
      ##
      additionalLabels: {}
      ## @param metrics.prometheusRule.rules Custom Prometheus [rules](https://prometheus.io/docs/prometheus/latest/configuration/alerting_rules/)
      ## These are just examples rules, please adapt them to your needs.
      ## Make sure to constraint the rules to the current postgresql service.
      ## rules:
      ##   - alert: HugeReplicationLag
      ##     expr: pg_replication_lag{service="{{ template "postgresql.fullname" . }}-metrics"} / 3600 > 1
      ##     for: 1m
      ##     labels:
      ##       severity: critical
      ##     annotations:
      ##       description: replication for {{ template "postgresql.fullname" . }} PostgreSQL is lagging by {{ "{{ $value }}" }} hour(s).
      ##       summary: PostgreSQL replication is lagging by {{ "{{ $value }}" }} hour(s).
      ##
      rules: []

cassandra-inject:
  replicaCount: 1  
  image:
    registry: docker.io
    repository: logimethods/smart-meter
    tag: cassandra-inject
  env:
    NATS_USERNAME_FILE: /secrets/nats_username_secret
    NATS_PASSWORD_FILE: /secrets/nats_password_secret
    NATS_NAME: smart-meter-nats.default.svc.cluster.local
    NATS_URI: smart-meter-nats.default.svc.cluster.local
    NATS_CLUSTER_ID: NB426DOHKZOZHBOABWKJYE73REVEIWMFTDBN5WKJZ2PMNE6SQMQ2D3BH
    CASSANDRA_URL: cassandra-cluster-main.default.svc.cluster.local
    CASSANDRA_INJECT_CONSISTENCY: ONE
    PING_ALLOWED: false
    NATS_SUBJECT: smartmeter.raw.voltage.data.>
    TASK_SLOT: "1"
  envFrom: []

  ## Please provide the volume mount configuration
  ##
  volumeMounts: 
    - name: nats-client-credentials
      readOnly: true
      mountPath: /secrets/
  
  ## Please provide the volumes to be mounted in the container
  ##
  volumes: 
  - name: nats-client-credentials
    secret:
      secretName: nats-client-credentials

nats:
  enabled: true
  image:
    registry: docker.io
    repository: bitnami/nats
    tag: 2.10.22-debian-12-r4
  replicaCount: 1
  ## Client Authentication
  ## ref: https://docs.nats.io/running-a-nats-service/configuration/securing_nats/auth_intro
  ## @param auth.enabled Switch to enable/disable client authentication
  ## @param auth.user Client authentication user
  ## @param auth.password Client authentication password
  ## @param auth.usersCredentials Client authentication users credentials collection
  ## Example:
  ## auth.usersCredentials:
  ##   - username: "a"
  ##     password: "b"
  auth:
    enabled: true
    user: natsuser_secret
    password: "natspwd_secret"
    usersCredentials: []
  ## Cluster Configuration
  ## ref: https://docs.nats.io/running-a-nats-service/configuration/clustering/cluster_config
  ##
  cluster:
    name: nats
    ## Cluster Authentication
    ## ref: https://docs.nats.io/running-a-nats-service/configuration/securing_nats/auth_intro
    ## @param cluster.auth.enabled Switch to enable/disable cluster authentication
    ## @param cluster.auth.user Cluster authentication user
    ## @param cluster.auth.password Cluster authentication password
    ##
    auth:
      enabled: true
      user: nats_cluster
      password: ""
  containerPorts:
    client: 4222
    cluster: 6222
    monitoring: 8222
  ## Metrics / Prometheus NATS Exporter
  ## ref: https://github.com/nats-io/prometheus-nats-exporter
  metrics:
    enabled: true
    ## @param metrics.flags [array] Flags to be passed to Prometheus metrics
    ##
    flags:
    - -connz
    - -routez
    - -subz
    - -varz
    ## Metrics service configuration
    ##
    service:
      ## @param metrics.service.type Kubernetes service type (`ClusterIP`, `NodePort` or `LoadBalancer`)
      ##
      type: ClusterIP
      ## @param metrics.service.port Prometheus metrics service port
      ##
      port: 7777
      ## @param metrics.service.loadBalancerIP Use serviceLoadBalancerIP to request a specific static IP, otherwise leave blank
      ##
      loadBalancerIP: ""
      ## @param metrics.service.annotations [object] Annotations for Prometheus metrics service
      ##
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "{{ .Values.metrics.service.port }}"
      ## @param metrics.service.labels Labels for Prometheus metrics service
      ##
      labels: {}
    ## Prometheus Operator ServiceMonitor configuration
    ##
    serviceMonitor:
      ## @param metrics.serviceMonitor.enabled Specify if a ServiceMonitor will be deployed for Prometheus Operator
      ##
      enabled: true
      ## @param metrics.serviceMonitor.namespace Namespace in which Prometheus is running
      ##
      namespace: default
      ## @param metrics.serviceMonitor.labels Extra labels for the ServiceMonitor
      ##
      labels: {}
      ## @param metrics.serviceMonitor.jobLabel The name of the label on the target service to use as the job name in Prometheus
      ##
      jobLabel: ""
      ## @param metrics.serviceMonitor.interval How frequently to scrape metrics
      ## e.g:
      ## interval: 10s
      ##
      interval: ""
      ## @param metrics.serviceMonitor.scrapeTimeout Timeout after which the scrape is ended
      ## e.g:
      ## scrapeTimeout: 10s
      ##
      scrapeTimeout: ""
      ## @param metrics.serviceMonitor.metricRelabelings [array] Specify additional relabeling of metrics
      ##
      metricRelabelings: []
      ## @param metrics.serviceMonitor.relabelings [array] Specify general relabeling
      ##
      relabelings: []
      ## @param metrics.serviceMonitor.selector Prometheus instance selector labels
      ## ref: https://github.com/bitnami/charts/tree/main/bitnami/prometheus-operator#prometheus-configuration
      ##
      selector: {}

  persistence:
    ## @param persistence.enabled Enable NATS data persistence using PVC(s)
    enabled: false
    storageClass: ""
    accessModes:
    - ReadWriteOnce
    size: 8Gi

graphite:
  enabled: true

cassandra:
  enabled: true
  initDBConfigMap: cassandra-init-scripts
  dbUser:
    password: password
 

kube-prometheus-stack:
  grafana:
    enabled: true
    #Used to set the admin password to access grafanna
    adminPassword: admin
    # Used to set up persistent volume for grafanna 
    ersistence:
      enabled: true
      accessModes:
      - ReadWriteOnce
    ingress:
      enabled: false
      ingressClassName: nginx
      annotations: {}
      hosts:
      - grafana.smart-meter
      tls:
      - hosts:
        - grafana.smart-meter
        secretName: grafana-tls

  alertmanager:
    enabled: false
  
  prometheus:
    enabled: true
    prometheusSpec:
      ## Interval between consecutive evaluations.
      evaluationInterval: 10s
      serviceMonitorSelectorNilUsesHelmValues: false